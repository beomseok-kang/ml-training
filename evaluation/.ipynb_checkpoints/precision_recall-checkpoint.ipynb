{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51656d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도 (precision) 와 재현율 (recall) 은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표이다.\n",
    "#\n",
    "# 정밀도 = TP / (FP + TP)\n",
    "# 재현율 = TP / (FN + TP)\n",
    "#\n",
    "# 정밀도는 예측을 Positive로 한 대상 중 예측과 실제 값이 Positive로 일치하는 데이터의 비율을 뜻한다.\n",
    "# 재현율은 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치하는 데이터의 비율을 뜻한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2186f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류 모델의 특성에 따라 특정 평가 지표가 더 중요한 지표로 간주될 수 있다.\n",
    "\n",
    "# 예를 들어 암 진단 모델의 경우, 재현율이 훨씬 중요한 지표이다.\n",
    "# 실제 Positive인 암 환자를 Positive가 아닌 Negative로 판단하였을 경우, 그 대가는 생명을 앗아갈 정도로 심각할 수 있기 때문이다. (재현율)\n",
    "# 그러나 실제 Negative인 암 환자를 Positive로 판단하는 것은 그저 재검사 한 번의 대가밖에 필요로 하지 않을 것이다. (정밀도)\n",
    "\n",
    "# 스팸메일 분류 모델의 경우에는 재현율이 더 중요하다.\n",
    "# 실제 스팸메일 (Positive) 인 메일을 Positive가 아닌 Negative로 판단한다 하더라도 사용자 입장에서 크게 손해볼 일은 없을 것이다. (재현율)\n",
    "# 그러나 스팸메일이 아닌 중요메일일 경우 (Negative) 만약 메일을 Negative가 아닌 Positive로 판단하는 것은\n",
    "# 사용자 입장에서 큰 손해를 입을 수도 있는 상황이다. (정밀도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e51da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Null 처리\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ed8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 예제에 있어서 예측 성능을 평가\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차행렬\\n', confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e39f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      " [[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbdc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
